2022-07-28 09:59:15,225 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='train', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 09:59:28,443 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-07-28 09:59:28,443 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 09:59:34,112 - utils - INFO - epoch: 0, step: 0, eta: 03:59:12, gen loss: 0.6344813704490662, mae loss: 0, adv_loss: 0, dis loss: 0
2022-07-28 09:59:57,510 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 10:00:10,294 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-07-28 10:00:10,294 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 10:03:25,153 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-07-28 10:03:38,292 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-07-28 10:03:38,292 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 10:22:10,731 - utils - INFO - epoch: 0, loss: 5.011585712432861, mae: 9.489639960921014, ssim: 0.9224302692544835, psnr: 23.51982693611408
2022-07-28 10:25:25,912 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_8_9', valid_weight=1.0, warmup_steps=1000)
2022-07-28 10:25:39,170 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-07-28 10:25:39,170 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 10:45:11,078 - utils - INFO - epoch: 0, loss: 3.2120094299316406, mae: 11.234714064308642, ssim: 0.8980980264875035, psnr: 22.045401062528843
2022-07-28 14:20:51,151 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_6_7', valid_weight=1.0, warmup_steps=1000)
2022-07-28 14:21:03,858 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-07-28 14:21:03,859 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 14:40:27,667 - utils - INFO - epoch: 0, loss: 1.6805354356765747, mae: 8.102136169233232, ssim: 0.9419080578200414, psnr: 25.103410542543692
2022-07-28 15:17:27,941 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_5_6', valid_weight=1.0, warmup_steps=1000)
2022-07-28 15:17:39,759 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-07-28 15:17:39,760 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 15:37:04,666 - utils - INFO - epoch: 0, loss: 1.2913599014282227, mae: 6.98888458348888, ssim: 0.956548779733792, psnr: 26.84385037447129
