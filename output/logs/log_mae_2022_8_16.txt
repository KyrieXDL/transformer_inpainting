2022-08-16 07:23:04,575 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_pos='last', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-08-16 07:23:36,557 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-08-16 07:23:36,557 - utils - INFO - msg: <All keys matched successfully>
2022-08-16 07:23:47,919 - utils - INFO - epoch: 0, loss: 2.435291051864624, mae: 8.51684404230442, ssim: 0.9415117751200197, psnr: 24.82213623328776
2022-08-16 07:26:39,126 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_pos='last', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-08-16 07:27:06,933 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-08-16 07:27:06,933 - utils - INFO - msg: <All keys matched successfully>
2022-08-16 07:27:19,484 - utils - INFO - epoch: 0, loss: 2.435291051864624, mae: 8.51684404230442, ssim: 0.9415117751200197, psnr: 24.82213623328776
2022-08-16 07:42:52,570 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_pos='last', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-08-16 07:43:20,578 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-08-16 07:43:20,579 - utils - INFO - msg: <All keys matched successfully>
2022-08-16 07:43:31,725 - utils - INFO - epoch: 0, loss: 2.435291051864624, mae: 8.51684404230442, ssim: 0.9415117751200197, psnr: 24.82213623328776
2022-08-16 07:46:12,403 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae/pytorch_model.bin', decoder_arch='transformer', decoder_depth=12, decoder_embed_dim=512, decoder_num_heads=16, depth=6, device_ids='2', embed_dim=768, epochs=30, flag='mae', fpn_type='2d', hole_weight=6.0, kv_downsample_layers='[4, 8]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=16, phase='val', pool_pos='last', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=False, use_fpn_loss=False, use_mae_loss=False, use_norm_pred=False, use_pconv=False, use_pyramid=False, use_random_mask=True, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-08-16 07:46:42,375 - utils - INFO - load ckpt from ./saved_models/mae/pytorch_model.bin
2022-08-16 07:46:42,375 - utils - INFO - msg: <All keys matched successfully>
2022-08-16 07:46:51,270 - utils - INFO - epoch: 0, loss: 2.435291051864624, mae: 8.51684404230442, ssim: 0.9415117751200197, psnr: 24.82213623328776
