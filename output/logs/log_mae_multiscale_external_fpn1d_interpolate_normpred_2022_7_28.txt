2022-07-28 07:12:45,818 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='0', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=4, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:13:03,228 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:13:03,228 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:14:29,999 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=4, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:14:45,274 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:14:45,274 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:17:59,119 - utils - INFO - Namespace(batchsize=64, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:18:12,623 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:18:12,623 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:20:33,348 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:20:48,229 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:20:48,229 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:42:24,029 - utils - INFO - epoch: 0, loss: 0.6362408995628357, mae: 4.1520679019656415, ssim: 0.9791144465817281, psnr: 30.83780323328498
2022-07-28 07:50:21,092 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:50:35,256 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:50:35,256 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:51:11,249 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:51:26,090 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:51:26,090 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:52:11,776 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:52:26,136 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:52:26,137 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 07:57:47,192 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 07:58:02,447 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 07:58:02,447 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 08:18:11,518 - utils - INFO - epoch: 0, loss: 0.6362408995628357, mae: 4.1520679019656415, ssim: 0.9791144465817281, psnr: 30.83780323328498
2022-07-28 08:21:58,028 - utils - INFO - Namespace(batchsize=128, checkpoint='', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='train', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks', valid_weight=1.0, warmup_steps=1000)
2022-07-28 08:22:22,826 - utils - INFO - epoch: 0, step: 0, eta: 03:42:21, gen loss: 115.31649017333984, mae loss: 0, adv_loss: 0, dis loss: 0
2022-07-28 08:30:08,254 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-07-28 08:30:23,358 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 08:30:23,358 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 08:31:15,944 - utils - INFO - epoch: 0, loss: 1.2987300157546997, mae: 5.742060044995786, ssim: 0.9550944277508542, psnr: 26.946906679213885
2022-07-28 08:32:48,915 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=12, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-07-28 08:33:04,015 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 08:33:04,015 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 08:53:40,785 - utils - INFO - epoch: 0, loss: 1.231189489364624, mae: 5.772389429910889, ssim: 0.9551438195851142, psnr: 26.901921757670742
2022-07-28 08:59:06,905 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=8, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_6_7', valid_weight=1.0, warmup_steps=1000)
2022-07-28 08:59:22,328 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 08:59:22,328 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 09:20:01,878 - utils - INFO - epoch: 0, loss: 0.9082965850830078, mae: 4.725448270229601, ssim: 0.9708763063350092, psnr: 28.93757511003978
2022-07-28 09:38:36,491 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=8, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_7_8', valid_weight=1.0, warmup_steps=1000)
2022-07-28 09:38:51,507 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 09:38:51,507 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 09:59:15,544 - utils - INFO - epoch: 0, loss: 1.231189489364624, mae: 5.772389429910889, ssim: 0.9551438195851142, psnr: 26.901921757670742
2022-07-28 10:24:23,795 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=8, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_8_9', valid_weight=1.0, warmup_steps=1000)
2022-07-28 10:24:39,190 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 10:24:39,191 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 10:45:10,844 - utils - INFO - epoch: 0, loss: 1.7380445003509521, mae: 7.20869970658203, ssim: 0.9323112758543799, psnr: 24.957089386272802
2022-07-28 14:19:31,836 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=8, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_6_7', valid_weight=1.0, warmup_steps=1000)
2022-07-28 14:19:47,250 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 14:19:47,251 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 14:40:52,096 - utils - INFO - epoch: 0, loss: 0.9082965850830078, mae: 4.725448270229601, ssim: 0.9708763063350092, psnr: 28.93757511003978
2022-07-28 15:17:21,584 - utils - INFO - Namespace(batchsize=128, checkpoint='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin', decoder_arch='multiscale_transformer', decoder_depth=12, decoder_embed_dim=768, decoder_num_heads=8, depth=6, device_ids='1', embed_dim=768, epochs=30, flag='mae_multiscale_external_fpn1d_interpolate_normpred', fpn_type='1d', hole_weight=6.0, kv_downsample_layers='[]', lr=5e-05, mae_hole_weight=1, mae_valid_weight=0, model_save_path='./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred', num_heads=12, num_workers=8, output_dir='./output/logs', patch_size=14, phase='val', pool_type='interpolate', prefetch=6, q_downsample_layers='[4, 8]', schedule_type='', seed=42, train_data_path='../data/celeba_train_data.txt', train_mask_path='../data/train_masks', use_adv=False, use_external_mask=True, use_fpn_loss=True, use_mae_loss=False, use_norm_pred=True, use_pconv=False, use_pyramid=False, use_random_mask=False, val_data_path='../data/celeba_val_data.txt', val_mask_path='../data/val_masks_5_6', valid_weight=1.0, warmup_steps=1000)
2022-07-28 15:17:35,756 - utils - INFO - load ckpt from ./saved_models/mae_multiscale_external_fpn1d_interpolate_normpred/pytorch_model.bin
2022-07-28 15:17:35,756 - utils - INFO - msg: <All keys matched successfully>
2022-07-28 15:38:32,716 - utils - INFO - epoch: 0, loss: 0.6428704857826233, mae: 3.950651017401941, ssim: 0.9815254790023862, psnr: 31.150886059825766
